# Age Estimation in Make-up (Cosmetics) Using Color and Depth Images

### Link to the paper:
- https://www.researchgate.net/publication/336955775_Age_Estimation_in_Make-up_Cosmetics_Using_Color_and_Depth_Images
- Or
- https://en.civilica.com/doc/1005989/
### Please cite:
- Mousavi, Seyed Muhammad Hossein and Lyashenko, Vyacheslav,1398,Age Estimation in Make-up (Cosmetics) Using Color and Depth Images,3rd International Conference on Soft Computing,Rudsar,https://civilica.com/doc/1005989
- Or
- Mousavi, Seyed Muhammad Hossein, and Vyacheslav Lyashenko. "Age Estimation in Make-up (Cosmetics) Using Color and Depth Images.",3rd International Conference on Soft Computing, Rudsar, Iran (2019).

## ABSTRACT

<div align="justify">

Age estimation in makeup (cosmetics) has application in surveillance and security. Traditional estimation systems used to employ just color images to do this. Also, traditional methods use an algorithm to remove makeup first and then perform estimation process, but this paper uses a novel way by a new technique. It is possible to use depth images along with color images to estimate even stronger (even in absolute darkness). Kinect Version 2 sensor is employed in most of the experiments in this paper. Using depth sensor, it is possible to make 3-dimentional model of the face and extract wrinkles of the face which is hidden under makeup or cosmetics. This feature helps in age estimation process by estimating the number of wrinkles in the face. It is tried to use depth image along with color image to increase experiment accuracy in faces under makeup. Proposed method does not need training process and just one image is enough for estimation. It is 100 times faster in some databases but lower accuracy just as double in max. There is no research done before using depth data for age estimation in makeup, which makes this research unique. Also, a new face detection and extraction method out of depth images is proposed in the paper. A simple color-depth makeup-based dataset is presented which is recorded using Kinect V.2. Proposed method is tested with some benchmark makeup datasets and returned satisfactory and promising results.

</div>

![image](https://github.com/user-attachments/assets/96031ffa-f259-4d4e-9642-e37a71f1a8f2)
![image](https://github.com/user-attachments/assets/0cc8fef8-e86f-4094-b241-6b19bc702759)
![image](https://github.com/user-attachments/assets/5c45bde9-c290-4141-bca3-a920034f20fb)
![image](https://github.com/user-attachments/assets/67b013c0-dfc7-4bb8-b90d-77969c015396)
![image](https://github.com/user-attachments/assets/e6f08fba-655d-4339-a969-4f4f0950d674)
![image](https://github.com/user-attachments/assets/a3939050-1d89-4aef-be8f-7a407c42bc07)
![image](https://github.com/user-attachments/assets/c255ae24-48ed-41c9-844a-adfb9c2914ed)
